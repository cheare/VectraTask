{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+-------------------+------------------+----------------------+-------------------+\n",
      "|year|            energy|  prev_year_energy|       energy_delta|      danceability|prev_year_danceability| danceability_delta|\n",
      "+----+------------------+------------------+-------------------+------------------+----------------------+-------------------+\n",
      "|1920|0.4186995702005730|              null|               null|0.5157501432664760|                  null|               null|\n",
      "|1921|0.2411363461538462|0.4186995702005730|-0.1775632240467268|0.4321705128205130|    0.5157501432664760|-0.0835796304459630|\n",
      "|1922|0.2261726446280992|0.2411363461538462|-0.0149637015257470|0.5756198347107437|    0.4321705128205130| 0.1434493218902307|\n",
      "|1923|0.2624064864864865|0.2261726446280992| 0.0362338418583873|0.5773405405405401|    0.5756198347107437| 0.0017207058297964|\n",
      "|1924|0.3443466101694912|0.2624064864864865| 0.0819401236830047|0.5498940677966102|    0.5773405405405401|-0.0274464727439299|\n",
      "+----+------------------+------------------+-------------------+------------------+----------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DecimalType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "def _read_csv(spark: SparkSession,\n",
    "              filepath: str) -> DataFrame:\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"year\", StringType()),\n",
    "        StructField(\"acousticness\", StringType()),\n",
    "        StructField(\"danceability\", DecimalType(17, 16)),\n",
    "        StructField(\"duration_ms\", StringType()),\n",
    "        StructField(\"energy\", DecimalType(17, 16)),\n",
    "        StructField(\"instrumentalness\", StringType()),\n",
    "        StructField(\"liveness\", StringType()),\n",
    "        StructField(\"loudness\", StringType()),\n",
    "        StructField(\"speechiness\", StringType()),\n",
    "        StructField(\"tempo\", StringType()),\n",
    "        StructField(\"valence\", StringType()),\n",
    "        StructField(\"popularity\", StringType()),\n",
    "        StructField(\"key\", StringType()),\n",
    "        StructField(\"mode\", StringType())\n",
    "    ])\n",
    "\n",
    "    df = spark.read.csv(\n",
    "        path=filepath,\n",
    "        sep=\",\",\n",
    "        header=True,\n",
    "        quote='\"',\n",
    "        encoding=\"UTF-8\",\n",
    "        schema=schema\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _add_prev_years(df: DataFrame) -> DataFrame:\n",
    "    window_fun = Window.partitionBy().orderBy(\"year\")\n",
    "\n",
    "    return df \\\n",
    "        .withColumn(\"prev_year_danceability\", F.lag(F.col(\"danceability\")).over(window_fun)) \\\n",
    "        .withColumn(\"prev_year_energy\", F.lag(F.col(\"energy\")).over(window_fun))\n",
    "\n",
    "\n",
    "def _calculate_delta(df: DataFrame) -> DataFrame:\n",
    "    return df \\\n",
    "        .withColumn(\"danceability_delta\", F.col(\"danceability\") - F.col(\"prev_year_danceability\")) \\\n",
    "        .withColumn(\"energy_delta\", F.col(\"energy\") - F.col(\"prev_year_energy\"))\n",
    "\n",
    "\n",
    "def main():\n",
    "    spark = SparkSession.builder.appName(\"vectra_task\").getOrCreate()\n",
    "\n",
    "    RAW_DATA_LOCATION = \"./data_by_year.csv\"\n",
    "\n",
    "    df_raw = _read_csv(\n",
    "        spark=spark,\n",
    "        filepath=RAW_DATA_LOCATION)\n",
    "    df_prev_years = _add_prev_years(df=df_raw)\n",
    "    df_delta = _calculate_delta(df=df_prev_years)\n",
    "\n",
    "    df_delta \\\n",
    "        .select(\n",
    "            F.col(\"year\"),\n",
    "            F.col(\"energy\"),\n",
    "            F.col(\"prev_year_energy\"),\n",
    "            F.col(\"energy_delta\"),\n",
    "            F.col(\"danceability\"),\n",
    "            F.col(\"prev_year_danceability\"),\n",
    "            F.col(\"danceability_delta\")\n",
    "        ).show(5)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_add_prev_years (__main__.TestVectraTask) ... /opt/conda/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 59022), raddr=('127.0.0.1', 43201)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/conda/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 44104), raddr=('127.0.0.1', 37727)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "ok\n",
      "test_calculate_delta (__main__.TestVectraTask) ... /opt/conda/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 38644), raddr=('127.0.0.1', 38551)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/conda/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 59612), raddr=('127.0.0.1', 46637)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 3.154s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "class TestVectraTask(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.spark = SparkSession.builder.appName(\"vectra_task_test\").getOrCreate()\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        cls.spark.stop()\n",
    "\n",
    "    def test_add_prev_years(self):\n",
    "        input_df = self.spark.createDataFrame(\n",
    "            [\n",
    "                (\"2000\", 0.3, 0.2),\n",
    "                (\"2001\", 0.5, 0.3),\n",
    "                (\"2002\", 0.1, 0.3),\n",
    "            ],\n",
    "            [\"year\", 'energy', 'danceability']\n",
    "        )\n",
    "        expected_output = self.spark.createDataFrame(\n",
    "            [\n",
    "                (\"2000\", 0.3, 0.2, None, None),\n",
    "                (\"2001\", 0.5, 0.3, 0.2, 0.3),\n",
    "                (\"2002\", 0.1, 0.3, 0.3, 0.5),\n",
    "            ],\n",
    "            [\"year\", 'energy', 'danceability', 'prev_year_danceability', 'prev_year_energy']\n",
    "        )\n",
    "        pd.testing.assert_frame_equal(_add_prev_years(input_df).toPandas(), expected_output.toPandas())\n",
    "\n",
    "    def test_calculate_delta(self):\n",
    "        input_df = self.spark.createDataFrame(\n",
    "            [\n",
    "                (\"2000\", 0.3, 0.2, None, None),\n",
    "                (\"2001\", 0.5, 0.3, 0.2, 0.3),\n",
    "                (\"2002\", 0.1, 0.3, 0.3, 0.5),\n",
    "            ],\n",
    "            [\"year\", 'energy', 'danceability', 'prev_year_danceability', 'prev_year_energy']\n",
    "        )\n",
    "        expected_output = self.spark.createDataFrame(\n",
    "            [\n",
    "                (\"2000\", 0.3, 0.2, None, None, None, None),\n",
    "                (\"2001\", 0.5, 0.3, 0.2, 0.3, 0.1, 0.2),\n",
    "                (\"2002\", 0.1, 0.3, 0.3, 0.5, 0.0, -0.4),\n",
    "            ],\n",
    "            [\"year\", 'energy', 'danceability', 'prev_year_danceability', 'prev_year_energy', \"danceability_delta\",\n",
    "             \"energy_delta\"]\n",
    "        )\n",
    "        pd.testing.assert_frame_equal(_calculate_delta(input_df).toPandas(), expected_output.toPandas())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['ignored', '-v'], exit=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
